# -*- coding: utf-8 -*-
"""covid.19.causes.shitdone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D8J-1u8Q41bFiYvC36MgBSGTIQmpVTuL
"""

!pip install watermark

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext watermark
# %watermark -v -p numpy,pandas,torch

import torch
import os
import numpy as np
import seaborn as sns
from matplotlib import rc
from sklearn.preprocessing import MinMaxScaler
from pandas.plotting import register_matplotlib_converters
from torch import nn, optim
import pandas as pd
from matplotlib import pyplot as plt
from torch.utils.data import Dataset, DataLoader
from datetime import datetime

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'
sns.set(style="whitegrid", palette="muted", font_scale=1.2)
HAPPY_COLORS_PALETTE = ["#01BEFE", "#FFDD00", "#FF7D00", "#FF006D", "#93D30C", "#8F00FF"]

sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))
register_matplotlib_converters()
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)

!wget https://raw.githubusercontent.com/CSSEGISandData/COVID-19/refs/heads/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv

df = pd.read_csv('time_series_covid19_confirmed_global.csv')

df.shape

df.head()

## get rid of first four columns
df = df.iloc[:, 4:]

df.head()

## check for missing values

df.isnull().sum().sum()

daily_cases = df.sum(axis=0)
daily_cases.index = pd.to_datetime(daily_cases.index)
daily_cases.head(), daily_cases.shape

plt.plot(daily_cases)

daily_cases = daily_cases.diff().fillna(daily_cases[0]).astype(np.int64)
daily_cases.head()

plt.plot(daily_causes)

daily_cases.shape

test_data_size = 200
train_data = daily_cases[:-test_data_size]
test_data = daily_cases[-test_data_size:]

train_data.shape, test_data.shape

scaler = MinMaxScaler()
scaler = scaler.fit(np.expand_dims(train_data, axis=1))
train_data = scaler.transform(np.expand_dims(train_data, axis=1))
test_data = scaler.transform(np.expand_dims(test_data, axis=1))

def create_sequences(data, seq_length):
    xs = []
    ys = []
    for i in range(len(data)-seq_length-1):
        x = data[i:(i+seq_length)]
        y = data[i+seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

seq_length = 5
### this means we want to consider each points with the 4 last of it
## because the old data matters to us so the number of data increases 5 times

X_train, y_train = create_sequences(train_data, seq_length)
X_test, y_test = create_sequences(test_data, seq_length)

X_train = torch.from_numpy(X_train).float()
y_train = torch.from_numpy(y_train).float()
X_test = torch.from_numpy(X_test).float()
y_test = torch.from_numpy(y_test).float()

X_train.shape, y_train.shape, X_test.shape, y_test.shape

train_data[:10]

class CoronaVirusPredictor(nn.Module):
    def __init__(self, n_features, n_hidden, seq_len, n_layers):
        super(CoronaVirusPredictor, self).__init__()

        self.n_hidden = n_hidden
        self.seq_len = seq_len
        self.n_layers = n_layers

        self.lstm = nn.LSTM(
            input_size=n_features,
            hidden_size=n_hidden,
            num_layers=n_layers,
            dropout=0.5
        )

        self.linear = nn.Linear(in_features=n_hidden, out_features=1)

    def reset_hidden_state(self):
      self.hidden = (
          torch.zeros(self.n_layers, self.seq_len, self.n_hidden),
          torch.zeros(self.n_layers, self.seq_len, self.n_hidden)
      )

    def forward(self, sequences):
        lstm_out, self.hidden = self.lstm(
            sequences.view(len(sequences), self.seq_len, -1),
            self.hidden
        )
        last_time_step = lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]
        y_pred = self.linear(last_time_step)
        return y_pred

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

def train_model(
    model,
    train_data,
    train_labels,
    test_data=None,
    test_labels=None
):
  loss_fn = nn.MSELoss().to(device)
  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)

  num_epochs = 60

  train_hist = np.zeros(num_epochs)
  test_hist = np.zeros(num_epochs)

  for t in range(num_epochs):
    model.reset_hidden_state()
    y_pred = model(X_train)

    loss = loss_fn(y_pred.float(), y_train)

    if test_data is not None:
      with torch.no_grad():
        y_test_pred = model(X_test)
        test_loss = loss_fn(y_test_pred.float(), y_test)
      test_hist[t] = test_loss.item()

      if t % 10 == 0:
        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')
    elif t % 10 == 0:
      print(f'Epoch {t} train loss: {loss.item()}')

    train_hist[t] = loss.item()

    optimiser.zero_grad()
    loss.backward()
    optimiser.step()

  return model.eval(), train_hist, test_hist

model = CoronaVirusPredictor(
    n_features=1,
    n_hidden=512,
    seq_len=seq_length,
    n_layers=2
)

from tqdm import tqdm

model, train_hist, test_hist = tqdm(train_model(
    model,
    X_train,
    y_train,
    X_test,
    y_test
))

plt.plot(train_hist, label='train loss')
plt.plot(test_hist, label='test loss')
plt.legend()

### use the predicted last one to predict the next prediction after the prediction

with torch.no_grad():
  test_seq = X_test[-1:]
  preds = []

  for _ in range(len(X_test)):
    y_test_pred = model(test_seq)
    pred = torch.flatten(y_test_pred).item()
    preds.append(pred)
    new_seq = test_seq.numpy().flatten()
    new_seq = np.append(new_seq, [pred])
    new_seq = new_seq[1:]
    test_seq = torch.as_tensor(new_seq).view(1, seq_length).float()

true_cases = scaler.inverse_transform(y_test.numpy()) # remove extra dimension, scaler expects 2D input
pred_cases = scaler.inverse_transform(np.array(preds).reshape(-1, 1)) # Reshape preds to be 2D (samples x features)

plt.plot(daily_cases.index[:len(train_data)], scaler.inverse_transform(train_data).flatten(), label='train')
plt.plot(daily_cases.index[len(train_data):len(train_data)+len(test_data)], true_cases.flatten(), label='test actual')
plt.plot(daily_cases.index[len(train_data):len(train_data)+len(test_data)], pred_cases.flatten(), label='test predicted')
plt.legend();

scaler = MinMaxScaler()
scaler = scaler.fit(np.expand_dims(daily_cases, axis=1))
all_data = scaler.transform(np.expand_dims(daily_cases, axis=1))

all_data.shape

X_all, y_all = create_sequences(all_data, seq_length)
X_all = torch.from_numpy(X_all).float()
y_all = torch.from_numpy(y_all).float()

model = CoronaVirusPredictor(
    n_features=1,
    n_hidden=512,
    seq_len=seq_length,
    n_layers=2
)

model, train_hist, _ = train_model(
    model,
    X_all,
    y_all
)

Days_to_predict = 12

with torch.no_grad():
  test_seq = X_all[-1:]
  preds = []
  for _ in range(Days_to_predict):
    y_test_pred = model(test_seq)
    pred = torch.flatten(y_test_pred).item()
    preds.append(pred)
    new_seq = test_seq.numpy().flatten()
    new_seq = np.append(new_seq, [pred])
    new_seq = new_seq[1:]
    test_seq = torch.as_tensor(new_seq).view(1, seq_length).float()

predicted_cases = scaler.inverse_transform(np.expand_dims(preds, axis=0)).flatten()

daily_cases.index[-1]

predicted_index = pd.date_range(
    start=daily_cases.index[-1],
    periods=Days_to_predict+1,
    closed='right'
)
predicted_cases = pd.Series(
    data=predicted_cases,
    index=predicted_index
)

plt.plot(predicted_cases, label='predicted')
plt.plot(daily_cases, label='actual')
plt.legend()

plt.plot(daily_cases, label="historical daily cases")
plt.plot(predicted_cases, label="predicted daily cases")
plt.legend();

